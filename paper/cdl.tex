\documentclass{article} % For LaTeX2e
\usepackage{nips13submit_e,times}
\usepackage{hyperref}
\usepackage[noabbrev]{cleveref}
\usepackage{url}
\usepackage{brian}
\usepackage{booktabs}
\usepackage{graphicx}
% \usepackage{microtype}
\usepackage[sort]{natbib}
%\documentstyle[nips13submit_09,times,art10]{article} % For LaTeX 2.09


\title{Efficient convolutional dictionary learning}


\author{
David S.~Hippocampus\thanks{ Use footnote for providing further information
about author (webpage, alternative address)---\emph{not} for acknowledging
funding agencies.} \\
Department of Computer Science\\
Cranberry-Lemon University\\
Pittsburgh, PA 15213 \\
\texttt{hippo@cs.cranberry-lemon.edu}
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

%\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


\maketitle

\begin{abstract}
We make convolutional coding faster.
\end{abstract}

\section{Introduction}
\cite{mairal2010}

\subsection{Related work}

\subsection{Preliminaries}
$\F:\R^d\rightarrow\C^d$ will denote the discrete Fourier transform, and $*$ will denote
convolution.
Time-domain signals will be represented by lower-case letters, \eg, $x \in \R^d$, while
frequency-domain representations will be denoted by capitals, $\F\{x\} = X \in \C^d$.

\section{Convolutional coding}
\label{sec:convcode}
Given a set of $m$ codewords ${\{d_k\}}_{k=1}^m \subset \R^d$ and a signal $x\in\R^d$, 
we would like to find a set of activation functions ${\{a_k\}}_{k=1}^m\subset\R^d$ which
can be used to reconstruct $x$ by convolving with the codewords:
\begin{align}
x &\approx \sum_{k=1}^m d_k * a_k.\label{eq:convapprox}
\end{align}
Because this parameterization increases the dimensionality of the representation from $d$ 
to $md$, we also desire that each activation function $a_k$ be sparse.  Formally, this is 
achieved by solving the following optimization problem:
\begin{align}
a(x) &\defeq \argmin_{\{a_k\}} \frac{1}{2} \left\|x - \sum_{k=1}^m d_k * a_k\right\|_2^2 +
\lambda \sum_{k=1}^m \omega(a_k), \label{eq:sisc}
\end{align}
where $\omega$ is a convex, sparsity-promoting regularization function (\eg, the 
$\ell_1$-norm), and $\lambda > 0 $ is a parameter to balance regularization against 
reconstruction accuracy. 

Because convolution is a linear operation, \eqref{eq:sisc} is convex in $a_k$.  
However, direct optimization is difficult.

\subsection{Coding in the frequency domain}
By applying Parseval's theorem and the convolution theorem,\footnote{We assume circular
convolutions throughout this article. However, linear convolutions can be accommodated
in the usual way by appropriate padding and truncation.} we can equivalently express the 
reconstruction term of \eqref{eq:sisc} in the frequency domain:\footnote{To ease
presentation, we assume the symmetrically normalized form of the Fourier transform, 
so that $\|x\| = \|\F\{x\}\|$. In general, a normalization constant may be included, 
or absorbed into the regularization parameter $\lambda$.}
\begin{align}
\left\|x - \sum_k d_k * a_k\right\|_2^2 &= \left\|\F\left\{x - \sum_k d_k *
a_k\right\}\right\|_2^2
= \left\| X - \sum_k D_k \circ A_k\right\|_2^2,\label{eq:fourier}
\end{align}
where the last equality follows by linearity of the Fourier transform, and $\circ$
denotes the Hadamard product: ${[u\circ v]}_i \defeq u_i v_i$.

While the right-hand side of \eqref{eq:fourier} nearly resembles a standard
least-squares objective, it can be put into a more familiar form via the following
lemma.
\begin{lemma}
Let $\{D_1, D_2, \dots, D_m\}, \{A_1, A_2, \dots, A_m\} \subset \C^d$.  
Then there exist matrices ${U \in \C^{d\times dm}}$, ${V \in \C^{dm}}$ such that 
${UV = \sum_{k=1}^m D_k \circ A_k}$.
\end{lemma}
\begin{proof}
$D_k$ and $A_k$ can be rearranged as follows:
\begin{align*}
U &\defeq \diagb(\{D_k\}) = \left[\diag(D_1), \diag(D_2), \dots, \diag(D_m)\right] \in \C^{d\times dm}\\
V &\defeq \vectorize(\{A_k\}) = \left[A_1\trans, A_2\trans, \dots,
A_m\trans\right]\trans \in \C^{dm}\\
\Rightarrow \quad {[UV]}_i &= \sum_k U_{ik} V_i = \sum_k [D_k]_i [A_k]_i = \sum_k [D_k \circ A_k]_i.
\end{align*}
\end{proof}


\subsection{ADMM solver}
\cite{boyd2011}

\subsection{Time-domain regularization}


\section{Dictionary learning}

\section{Experiments}
\section{Conclusion}

\bibliographystyle{plain}
\bibliography{refs}

\end{document}
